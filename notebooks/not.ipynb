{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ab2b0bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f1d8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to PYTHONPATH: /Users/evamartin/Desktop/MDS/curs3/AML/projects/AML-Project3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"Project root added to PYTHONPATH:\", PROJECT_ROOT)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from src.data.preprocess import load_data, preprocess_fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38836b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (30000, 23)\n",
      "y shape: (30000,)\n",
      "\n",
      "Class distribution:\n",
      "default\n",
      "0    0.7788\n",
      "1    0.2212\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/data.csv\"\n",
    "TARGET = \"default\"\n",
    "\n",
    "X, y = load_data(DATA_PATH, TARGET)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"\\nClass distribution:\")\n",
    "print(y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "505f7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b24aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (24000, 23)\n",
      "Test shape: (6000, 23)\n"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = next(cv.split(X, y))\n",
    "\n",
    "fold_data = preprocess_fold(\n",
    "    X, y,\n",
    "    train_idx, test_idx,\n",
    "    winsorize=False\n",
    ")\n",
    "\n",
    "Xtr = fold_data[\"X_train\"]\n",
    "Xte = fold_data[\"X_test\"]\n",
    "ytr = fold_data[\"y_train\"]\n",
    "yte = fold_data[\"y_test\"]\n",
    "\n",
    "print(\"Train shape:\", Xtr.shape)\n",
    "print(\"Test shape:\", Xte.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecafc6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean (abs): 4.049578707792166e-17\n",
      "Train std: 1.0000208339843975\n",
      "Test mean (abs): 0.012427657996872699\n",
      "Test std: 1.0717407042108311\n"
     ]
    }
   ],
   "source": [
    "print(\"Train mean (abs):\", Xtr.mean().abs().mean())\n",
    "print(\"Train std:\", Xtr.std().mean())\n",
    "\n",
    "print(\"Test mean (abs):\", Xte.mean().abs().mean())\n",
    "print(\"Test std:\", Xte.std().mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5589e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With winsorization:\n",
      "Mean abs: 5.0510320563815817e-17\n",
      "Std: 1.0000208339843975\n"
     ]
    }
   ],
   "source": [
    "fold_data_w = preprocess_fold(\n",
    "    X, y,\n",
    "    train_idx, test_idx,\n",
    "    winsorize=True\n",
    ")\n",
    "\n",
    "Xtr_w = fold_data_w[\"X_train\"]\n",
    "\n",
    "print(\"With winsorization:\")\n",
    "print(\"Mean abs:\", Xtr_w.mean().abs().mean())\n",
    "print(\"Std:\", Xtr_w.std().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73895a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': np.float64(0.7244675405388677),\n",
       " 'pr_auc': np.float64(0.5016627284852238),\n",
       " 'log_loss': 0.4657501909229874,\n",
       " 'brier': np.float64(0.14510045548514897),\n",
       " 'f1': 0.3628169014084507,\n",
       " 'balanced_accuracy': np.float64(0.6078573712658855)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.logistic import train_logistic\n",
    "from evaluation.metrics import evaluate_model\n",
    "\n",
    "model, y_prob = train_logistic(Xtr, ytr, Xte)\n",
    "\n",
    "metrics = evaluate_model(yte, y_prob)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6929db03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default\n",
       "0    23364\n",
       "1     6636\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "369a218b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': np.float64(0.7872542717960884),\n",
       " 'pr_auc': np.float64(0.5603562617478409),\n",
       " 'log_loss': 0.45852037443793414,\n",
       " 'brier': np.float64(0.14547420623135726),\n",
       " 'f1': 0.554773082942097,\n",
       " 'balanced_accuracy': np.float64(0.7113991067007757)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.random_forest import train_random_forest\n",
    "from evaluation.metrics import evaluate_model\n",
    "\n",
    "rf_model, rf_prob = train_random_forest(Xtr, ytr, Xte)\n",
    "\n",
    "rf_metrics = evaluate_model(yte, rf_prob)\n",
    "rf_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81110ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': np.float64(0.7914176773446526),\n",
       " 'pr_auc': np.float64(0.5484803806314421),\n",
       " 'log_loss': 0.4248297126580792,\n",
       " 'brier': np.float64(0.13332380025581247),\n",
       " 'f1': 0.47642197374817696,\n",
       " 'balanced_accuracy': np.float64(0.6589100408483248)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.boosting import train_boosting\n",
    "from evaluation.metrics import evaluate_model\n",
    "\n",
    "gb_model, gb_prob = train_boosting(Xtr, ytr, Xte)\n",
    "\n",
    "gb_metrics = evaluate_model(yte, gb_prob)\n",
    "gb_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5420abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 19200, d: 23, and nval: 4800\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 16.75937509536743 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 13.78135871887207 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 12.78040599822998 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 12.97499680519104 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 12.524492979049683 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [01:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': np.float64(0.7406024193090857),\n",
       " 'pr_auc': np.float64(0.49155697512140567),\n",
       " 'log_loss': 0.5322042371664031,\n",
       " 'brier': np.float64(0.15055783885954827),\n",
       " 'f1': 0.4444444444444444,\n",
       " 'balanced_accuracy': np.float64(0.6430477904769764)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "xrfm_model, xrfm_prob = train_xrfm(Xtr, ytr, Xte)\n",
    "xrfm_metrics = evaluate_model(yte, xrfm_prob)\n",
    "xrfm_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "121e088e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got DataFrame)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _, val_prob \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_xrfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(val_prob\u001b[38;5;241m.\u001b[39mshape, val_prob\u001b[38;5;241m.\u001b[39mmin(), val_prob\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/Desktop/MDS/curs3/AML/projects/AML-Project3/models/xrfm.py:37\u001b[0m, in \u001b[0;36mtrain_xrfm\u001b[0;34m(X_train, y_train, X_test, device, tuning_metric, **rfm_kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# 2) Convert to float32 torch tensors\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m X_train_t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     38\u001b[0m y_train_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_train\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m X_test_t  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got DataFrame)"
     ]
    }
   ],
   "source": [
    "_, val_prob = train_xrfm(X_tr2, y_tr2, X_val2)\n",
    "print(val_prob.shape, val_prob.min(), val_prob.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aef730b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 23, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.989893913269043 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.7895307540893555 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.431349992752075 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.824734926223755 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.4753060340881348 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:22<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "(8000,) 0.001 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from models.xx import train_xrfm\n",
    "\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "tr_idx, val_idx = next(inner_cv.split(Xtr, ytr))\n",
    "\n",
    "X_tr2 = Xtr.iloc[tr_idx]\n",
    "y_tr2 = ytr.iloc[tr_idx]\n",
    "X_val2 = Xtr.iloc[val_idx]\n",
    "\n",
    "# esto es EXACTAMENTE lo que stacking hace\n",
    "_, val_prob = train_xrfm(X_tr2, y_tr2, X_val2)\n",
    "\n",
    "print(val_prob.shape, val_prob.min(), val_prob.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a41bab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.logistic import train_logistic\n",
    "from models.random_forest import train_random_forest\n",
    "from models.boosting import train_boosting\n",
    "from models.stacking import train_stacking\n",
    "from evaluation.metrics import evaluate_model\n",
    "\n",
    "base_models_fast = {\n",
    "    \"logistic\": train_logistic,\n",
    "    \"rf\": train_random_forest,\n",
    "    \"gb\": train_boosting,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b9343b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating OOF predictions for logistic\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "Generating OOF predictions for rf\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "Generating OOF predictions for gb\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': np.float64(0.7939362866706552),\n",
       " 'pr_auc': np.float64(0.5662343820640482),\n",
       " 'log_loss': 0.42294460715184307,\n",
       " 'brier': np.float64(0.1323456771767259),\n",
       " 'f1': 0.4744773942634905,\n",
       " 'balanced_accuracy': np.float64(0.6579429877042416)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_model, stack_prob = train_stacking(\n",
    "    Xtr, ytr, Xte,\n",
    "    base_models=base_models_fast,\n",
    "    n_splits=3\n",
    ")\n",
    "\n",
    "evaluate_model(yte, stack_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bfb93cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating OOF predictions for logistic\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "Generating OOF predictions for rf\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "Generating OOF predictions for gb\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating OOF predictions for xrfm\n",
      "  Inner fold 1/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 23, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.781532049179077 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.716062068939209 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.7817418575286865 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.5484349727630615 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.9374899864196777 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:24<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 23, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.705414056777954 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.390803098678589 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.58070707321167 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.4373340606689453 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.985748052597046 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:21<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 2/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 23, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.8490869998931885 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.43896484375 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.446969985961914 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.3814690113067627 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.447479009628296 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:21<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 23, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.786815881729126 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.693286895751953 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.5517830848693848 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.3865201473236084 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.411823034286499 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:21<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 3/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 23, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.052418947219849 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.629703998565674 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.394035816192627 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.7090930938720703 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.7287979125976562 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:21<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 23, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.4065728187561035 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.3845622539520264 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.266696214675903 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.398921251296997 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.313722848892212 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': np.float64(0.7934972445432416),\n",
       " 'pr_auc': np.float64(0.565097559700661),\n",
       " 'log_loss': 0.423196126905582,\n",
       " 'brier': np.float64(0.13243919656713043),\n",
       " 'f1': 0.4692682926829268,\n",
       " 'balanced_accuracy': np.float64(0.655307445535567)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_models_full = {\n",
    "    \"logistic\": train_logistic,\n",
    "    \"rf\": train_random_forest,\n",
    "    \"gb\": train_boosting,\n",
    "    \"xrfm\": train_xrfm,\n",
    "}\n",
    "\n",
    "stack_model, stack_prob = train_stacking(\n",
    "    Xtr, ytr, Xte,\n",
    "    base_models=base_models_full,\n",
    "    n_splits=3   # mantenlo bajo para no esperar horas\n",
    ")\n",
    "\n",
    "evaluate_model(yte, stack_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71938f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
