{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbe715e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from preprocessing.preprocess import load_data, preprocess_fold\n",
    "from evaluation.metrics import evaluate_model\n",
    "from models.logistic import train_logistic\n",
    "from models.random_forest import train_random_forest\n",
    "from models.boosting import train_boosting\n",
    "from models.xrfm import train_xrfm\n",
    "from models.stacking import train_stacking\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67f4a4",
   "metadata": {},
   "source": [
    "## Load data & folds from main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e417186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 folds\n",
      "Data shape: (30000, 23)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/data.csv\"\n",
    "TARGET = \"default\"\n",
    "FOLDS_PATH = \"../results/cv_folds.json\"\n",
    "\n",
    "X, y = load_data(DATA_PATH, TARGET)\n",
    "\n",
    "with open(FOLDS_PATH, \"r\") as f:\n",
    "    cv_folds = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(cv_folds)} folds\")\n",
    "print(f\"Data shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a1a4d",
   "metadata": {},
   "source": [
    "## 1. Ablation Study\n",
    "\n",
    "Remove each model from stacking and measure performance drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21dec49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_study(X, y, train_idx, test_idx, base_models, n_splits=3):\n",
    "    \"\"\"\n",
    "    Drop-one ablation: remove each model and measure delta.\n",
    "    Returns (results_list, full_meta_model) to avoid recomputation.\n",
    "    \"\"\"\n",
    "    fold_data = preprocess_fold(X, y, train_idx, test_idx, winsorize=False)\n",
    "    Xtr, ytr = fold_data[\"X_train\"], fold_data[\"y_train\"]\n",
    "    Xte, yte = fold_data[\"X_test\"], fold_data[\"y_test\"]\n",
    "    \n",
    "    # Full stacking (save meta_model)\n",
    "    full_meta_model, prob_full = train_stacking(\n",
    "        Xtr, ytr, Xte, base_models=base_models, n_splits=n_splits\n",
    "    )\n",
    "    metrics_full = evaluate_model(yte, prob_full)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Baseline: all models\n",
    "    results.append({\n",
    "        \"removed\": \"none\",\n",
    "        \"roc_auc\": metrics_full[\"roc_auc\"],\n",
    "        \"pr_auc\": metrics_full[\"pr_auc\"],\n",
    "        \"log_loss\": metrics_full[\"log_loss\"]\n",
    "    })\n",
    "    \n",
    "    # Remove each model\n",
    "    for name in base_models.keys():\n",
    "        bm_partial = {k: v for k, v in base_models.items() if k != name}\n",
    "        \n",
    "        _, prob_partial = train_stacking(\n",
    "            Xtr, ytr, Xte, base_models=bm_partial, n_splits=n_splits\n",
    "        )\n",
    "        metrics_partial = evaluate_model(yte, prob_partial)\n",
    "        \n",
    "        results.append({\n",
    "            \"removed\": name,\n",
    "            \"roc_auc\": metrics_partial[\"roc_auc\"],\n",
    "            \"pr_auc\": metrics_partial[\"pr_auc\"],\n",
    "            \"log_loss\": metrics_partial[\"log_loss\"],\n",
    "            \"delta_roc_auc\": metrics_partial[\"roc_auc\"] - metrics_full[\"roc_auc\"],\n",
    "            \"delta_pr_auc\": metrics_partial[\"pr_auc\"] - metrics_full[\"pr_auc\"],\n",
    "            \"delta_log_loss\": metrics_partial[\"log_loss\"] - metrics_full[\"log_loss\"]\n",
    "        })\n",
    "    \n",
    "    return results, full_meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f867528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STACKING] Base model: logistic\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: rf\n",
      "  Inner fold 1/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: rf\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: gb\n",
      "  Inner fold 1/3\n",
      "\n",
      "[STACKING] Base model: gb\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "  Inner fold 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STACKING] Base model: xrfm\n",
      "  Inner fold 1/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 5.0120038986206055 seconds\n",
      "Time taken for round 0: 5.0120038986206055 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 5.139962911605835 seconds\n",
      "Time taken for round 1: 5.139962911605835 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.455842018127441 seconds\n",
      "Time taken for round 2: 4.455842018127441 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.999077081680298 seconds\n",
      "Time taken for round 3: 4.999077081680298 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 4.360034942626953 seconds\n",
      "Time taken for round 4: 4.360034942626953 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:27<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.0272979736328125 seconds\n",
      "Time taken for round 0: 4.0272979736328125 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.70109486579895 seconds\n",
      "Time taken for round 1: 3.70109486579895 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.02788782119751 seconds\n",
      "Time taken for round 2: 4.02788782119751 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.821354866027832 seconds\n",
      "Time taken for round 3: 3.821354866027832 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.541029930114746 seconds\n",
      "Time taken for round 4: 3.541029930114746 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:23<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 2/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.8609142303466797 seconds\n",
      "Time taken for round 0: 3.8609142303466797 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.555102825164795 seconds\n",
      "Time taken for round 1: 3.555102825164795 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.7564148902893066 seconds\n",
      "Time taken for round 2: 3.7564148902893066 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.030278921127319 seconds\n",
      "Time taken for round 3: 4.030278921127319 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.6825690269470215 seconds\n",
      "Time taken for round 4: 3.6825690269470215 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:22<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.7289299964904785 seconds\n",
      "Time taken for round 0: 3.7289299964904785 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.708956003189087 seconds\n",
      "Time taken for round 1: 3.708956003189087 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.7244629859924316 seconds\n",
      "Time taken for round 2: 3.7244629859924316 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.343274831771851 seconds\n",
      "Time taken for round 3: 4.343274831771851 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 5.1189587116241455 seconds\n",
      "Time taken for round 4: 5.1189587116241455 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:26<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 3/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.144320964813232 seconds\n",
      "Time taken for round 0: 4.144320964813232 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.9475479125976562 seconds\n",
      "Time taken for round 1: 3.9475479125976562 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.4291739463806152 seconds\n",
      "Time taken for round 2: 3.4291739463806152 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.7447071075439453 seconds\n",
      "Time taken for round 3: 3.7447071075439453 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 4.4077229499816895 seconds\n",
      "Time taken for round 4: 4.4077229499816895 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.856807231903076 seconds\n",
      "Time taken for round 0: 4.856807231903076 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.788141965866089 seconds\n",
      "Time taken for round 1: 4.788141965866089 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.399719953536987 seconds\n",
      "Time taken for round 2: 4.399719953536987 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 5.198590993881226 seconds\n",
      "Time taken for round 3: 5.198590993881226 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 5.029860258102417 seconds\n",
      "Time taken for round 4: 5.029860258102417 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "\n",
      "[STACKING] Base model: rf\n",
      "  Inner fold 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: gb\n",
      "  Inner fold 1/3\n",
      "\n",
      "[STACKING] Base model: gb\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "  Inner fold 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STACKING] Base model: xrfm\n",
      "  Inner fold 1/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.371204137802124 seconds\n",
      "Time taken for round 0: 4.371204137802124 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.7157211303710938 seconds\n",
      "Time taken for round 1: 3.7157211303710938 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.853893280029297 seconds\n",
      "Time taken for round 2: 3.853893280029297 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.552372932434082 seconds\n",
      "Time taken for round 3: 4.552372932434082 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.991929054260254 seconds\n",
      "Time taken for round 4: 3.991929054260254 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:24<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.0901618003845215 seconds\n",
      "Time taken for round 0: 4.0901618003845215 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.255757093429565 seconds\n",
      "Time taken for round 1: 4.255757093429565 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.4993808269500732 seconds\n",
      "Time taken for round 2: 3.4993808269500732 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.834463119506836 seconds\n",
      "Time taken for round 3: 4.834463119506836 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 4.815423011779785 seconds\n",
      "Time taken for round 4: 4.815423011779785 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:26<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 2/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 5.440744876861572 seconds\n",
      "Time taken for round 0: 5.440744876861572 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.428037166595459 seconds\n",
      "Time taken for round 1: 4.428037166595459 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.168635845184326 seconds\n",
      "Time taken for round 2: 4.168635845184326 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.71039080619812 seconds\n",
      "Time taken for round 3: 3.71039080619812 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.3313868045806885 seconds\n",
      "Time taken for round 4: 3.3313868045806885 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:24<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.9627230167388916 seconds\n",
      "Time taken for round 0: 3.9627230167388916 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.7155067920684814 seconds\n",
      "Time taken for round 1: 3.7155067920684814 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.707082748413086 seconds\n",
      "Time taken for round 2: 3.707082748413086 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.807252883911133 seconds\n",
      "Time taken for round 3: 3.807252883911133 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 4.0309669971466064 seconds\n",
      "Time taken for round 4: 4.0309669971466064 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:24<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 3/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.23078727722168 seconds\n",
      "Time taken for round 0: 4.23078727722168 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.3385918140411377 seconds\n",
      "Time taken for round 1: 3.3385918140411377 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.863147020339966 seconds\n",
      "Time taken for round 2: 3.863147020339966 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.026206016540527 seconds\n",
      "Time taken for round 3: 4.026206016540527 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.895578145980835 seconds\n",
      "Time taken for round 4: 3.895578145980835 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:25<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.280013084411621 seconds\n",
      "Time taken for round 0: 4.280013084411621 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.7382872104644775 seconds\n",
      "Time taken for round 1: 3.7382872104644775 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.233839988708496 seconds\n",
      "Time taken for round 2: 4.233839988708496 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.486088991165161 seconds\n",
      "Time taken for round 3: 3.486088991165161 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.9133617877960205 seconds\n",
      "Time taken for round 4: 3.9133617877960205 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:23<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "\n",
      "[STACKING] Base model: logistic\n",
      "  Inner fold 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: gb\n",
      "  Inner fold 1/3\n",
      "\n",
      "[STACKING] Base model: gb\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "  Inner fold 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STACKING] Base model: xrfm\n",
      "  Inner fold 1/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.987000942230225 seconds\n",
      "Time taken for round 0: 4.987000942230225 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.9269020557403564 seconds\n",
      "Time taken for round 1: 3.9269020557403564 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.466697931289673 seconds\n",
      "Time taken for round 2: 4.466697931289673 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.875718116760254 seconds\n",
      "Time taken for round 3: 3.875718116760254 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 5.040549993515015 seconds\n",
      "Time taken for round 4: 5.040549993515015 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:26<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.170310020446777 seconds\n",
      "Time taken for round 0: 4.170310020446777 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.1078221797943115 seconds\n",
      "Time taken for round 1: 4.1078221797943115 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.060992002487183 seconds\n",
      "Time taken for round 2: 4.060992002487183 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.3077380657196045 seconds\n",
      "Time taken for round 3: 3.3077380657196045 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.8192951679229736 seconds\n",
      "Time taken for round 4: 3.8192951679229736 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:23<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 2/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 7.63971209526062 seconds\n",
      "Time taken for round 0: 7.63971209526062 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.192770004272461 seconds\n",
      "Time taken for round 1: 4.192770004272461 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.306803226470947 seconds\n",
      "Time taken for round 2: 4.306803226470947 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.6413192749023438 seconds\n",
      "Time taken for round 3: 3.6413192749023438 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.447404146194458 seconds\n",
      "Time taken for round 4: 3.447404146194458 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:26<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.8652660846710205 seconds\n",
      "Time taken for round 0: 3.8652660846710205 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.015006065368652 seconds\n",
      "Time taken for round 1: 4.015006065368652 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.4393680095672607 seconds\n",
      "Time taken for round 2: 3.4393680095672607 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.7935409545898438 seconds\n",
      "Time taken for round 3: 3.7935409545898438 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.714010000228882 seconds\n",
      "Time taken for round 4: 3.714010000228882 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:22<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 3/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.591707944869995 seconds\n",
      "Time taken for round 0: 4.591707944869995 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.9267568588256836 seconds\n",
      "Time taken for round 1: 3.9267568588256836 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 6.386642932891846 seconds\n",
      "Time taken for round 2: 6.386642932891846 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.405098915100098 seconds\n",
      "Time taken for round 3: 4.405098915100098 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 4.60322117805481 seconds\n",
      "Time taken for round 4: 4.60322117805481 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.719851016998291 seconds\n",
      "Time taken for round 0: 3.719851016998291 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.579433917999268 seconds\n",
      "Time taken for round 1: 4.579433917999268 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.874324083328247 seconds\n",
      "Time taken for round 2: 4.874324083328247 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.245087385177612 seconds\n",
      "Time taken for round 3: 4.245087385177612 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 4.015280246734619 seconds\n",
      "Time taken for round 4: 4.015280246734619 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:24<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "\n",
      "[STACKING] Base model: logistic\n",
      "  Inner fold 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: rf\n",
      "  Inner fold 1/3\n",
      "\n",
      "[STACKING] Base model: rf\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "  Inner fold 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STACKING] Base model: xrfm\n",
      "  Inner fold 1/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.864962816238403 seconds\n",
      "Time taken for round 0: 4.864962816238403 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.37072491645813 seconds\n",
      "Time taken for round 1: 4.37072491645813 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.054086923599243 seconds\n",
      "Time taken for round 2: 4.054086923599243 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.89646577835083 seconds\n",
      "Time taken for round 3: 3.89646577835083 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.6536569595336914 seconds\n",
      "Time taken for round 4: 3.6536569595336914 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:24<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.638702154159546 seconds\n",
      "Time taken for round 0: 4.638702154159546 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.228115081787109 seconds\n",
      "Time taken for round 1: 4.228115081787109 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.310065269470215 seconds\n",
      "Time taken for round 2: 4.310065269470215 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.6015889644622803 seconds\n",
      "Time taken for round 3: 3.6015889644622803 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.9774200916290283 seconds\n",
      "Time taken for round 4: 3.9774200916290283 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:24<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 2/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.507378339767456 seconds\n",
      "Time taken for round 0: 4.507378339767456 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.891777038574219 seconds\n",
      "Time taken for round 1: 4.891777038574219 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.403294086456299 seconds\n",
      "Time taken for round 2: 4.403294086456299 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.6556947231292725 seconds\n",
      "Time taken for round 3: 4.6556947231292725 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.8024790287017822 seconds\n",
      "Time taken for round 4: 3.8024790287017822 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:25<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 3.9572432041168213 seconds\n",
      "Time taken for round 0: 3.9572432041168213 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 3.6695408821105957 seconds\n",
      "Time taken for round 1: 3.6695408821105957 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 3.558669090270996 seconds\n",
      "Time taken for round 2: 3.558669090270996 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 3.7828500270843506 seconds\n",
      "Time taken for round 3: 3.7828500270843506 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 3.9883079528808594 seconds\n",
      "Time taken for round 4: 3.9883079528808594 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:23<?, ?it/s]\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n",
      "  Inner fold 3/3\n",
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.321484804153442 seconds\n",
      "Time taken for round 0: 4.321484804153442 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 4.354434967041016 seconds\n",
      "Time taken for round 1: 4.354434967041016 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 4.512938022613525 seconds\n",
      "Time taken for round 2: 4.512938022613525 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 4.38789701461792 seconds\n",
      "Time taken for round 3: 4.38789701461792 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 4.8035500049591064 seconds\n",
      "Time taken for round 4: 4.8035500049591064 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n",
      "Warning: Using floating point y with a classification metric. Assuming that y is already binarized / one-hot encoded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Fitting xRFM with 1 trees and 0 iterations per tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Fitting RFM with ntrain: 12800, d: 33, and nval: 3200\n",
      "======================================================================\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 0: 4.634217023849487 seconds\n",
      "Time taken for round 0: 4.634217023849487 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 1: 5.465370178222656 seconds\n",
      "Time taken for round 1: 5.465370178222656 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 2: 5.845360994338989 seconds\n",
      "Time taken for round 2: 5.845360994338989 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 3: 6.867566823959351 seconds\n",
      "Time taken for round 3: 6.867566823959351 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Time taken for round 4: 4.466023921966553 seconds\n",
      "Time taken for round 4: 4.466023921966553 seconds\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n",
      "Using cheap batch size\n",
      "Optimal M batch size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building trees:   0%|          | 0/1 [00:30<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree has no split, stopping training\n",
      "Using hard routing for tree prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STACKING] Base model: logistic\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: rf\n",
      "  Inner fold 1/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: rf\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "  Inner fold 3/3\n",
      "\n",
      "[STACKING] Base model: gb\n",
      "  Inner fold 1/3\n",
      "\n",
      "[STACKING] Base model: gb\n",
      "  Inner fold 1/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 2/3\n",
      "  Inner fold 3/3\n",
      "  Inner fold 3/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>removed</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>delta_roc_auc</th>\n",
       "      <th>delta_pr_auc</th>\n",
       "      <th>delta_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>0.794171</td>\n",
       "      <td>0.565065</td>\n",
       "      <td>0.421381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.795124</td>\n",
       "      <td>0.567645</td>\n",
       "      <td>0.420710</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>-0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.792649</td>\n",
       "      <td>0.555078</td>\n",
       "      <td>0.422789</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gb</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.561894</td>\n",
       "      <td>0.423981</td>\n",
       "      <td>-0.004048</td>\n",
       "      <td>-0.003171</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xrfm</td>\n",
       "      <td>0.794283</td>\n",
       "      <td>0.565479</td>\n",
       "      <td>0.421293</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>-0.000088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    removed   roc_auc    pr_auc  log_loss  delta_roc_auc  delta_pr_auc  \\\n",
       "0      none  0.794171  0.565065  0.421381            NaN           NaN   \n",
       "1  logistic  0.795124  0.567645  0.420710       0.000953      0.002580   \n",
       "2        rf  0.792649  0.555078  0.422789      -0.001522     -0.009987   \n",
       "3        gb  0.790123  0.561894  0.423981      -0.004048     -0.003171   \n",
       "4      xrfm  0.794283  0.565479  0.421293       0.000112      0.000414   \n",
       "\n",
       "   delta_log_loss  \n",
       "0             NaN  \n",
       "1       -0.000671  \n",
       "2        0.001409  \n",
       "3        0.002600  \n",
       "4       -0.000088  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_models = {\n",
    "    \"logistic\": train_logistic,\n",
    "    \"rf\": train_random_forest,\n",
    "    \"gb\": train_boosting,\n",
    "    \"xrfm\": train_xrfm,\n",
    "}\n",
    "\n",
    "# Run ablation on first fold for speed\n",
    "fold_1 = cv_folds[0]\n",
    "train_idx = np.array(fold_1[\"train_idx\"])\n",
    "test_idx = np.array(fold_1[\"test_idx\"])\n",
    "\n",
    "ablation_results, full_meta_model = ablation_study(\n",
    "    X, y, train_idx, test_idx, base_models, n_splits=3\n",
    ")\n",
    "\n",
    "df_ablation = pd.DataFrame(ablation_results)\n",
    "df_ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb8f37",
   "metadata": {},
   "source": [
    "Negative delta in ROC-AUC/PR-AUC means removing that model hurts performance (model is important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98d54c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize deltas\n",
    "df_plot = df_ablation[df_ablation[\"removed\"] != \"none\"].copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# ROC AUC delta\n",
    "axes[0].barh(df_plot[\"removed\"], df_plot[\"delta_roc_auc\"], color=\"steelblue\")\n",
    "axes[0].axvline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "axes[0].set_xlabel(\"Delta ROC-AUC\")\n",
    "axes[0].set_title(\"Impact of removing each model\")\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# PR AUC delta\n",
    "axes[1].barh(df_plot[\"removed\"], df_plot[\"delta_pr_auc\"], color=\"coral\")\n",
    "axes[1].axvline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "axes[1].set_xlabel(\"Delta PR-AUC\")\n",
    "axes[1].set_title(\"Impact of removing each model\")\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fd602",
   "metadata": {},
   "source": [
    "## 2. Meta-model coefficients\n",
    "\n",
    "Check what weights the logistic regression meta-learner assigns to each base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acbb32d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -3.3774\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.573558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>2.332980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gb</td>\n",
       "      <td>2.314686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xrfm</td>\n",
       "      <td>-0.057234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  coefficient\n",
       "0  logistic     0.573558\n",
       "1        rf     2.332980\n",
       "2        gb     2.314686\n",
       "3      xrfm    -0.057234"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use meta_model from ablation (no retraining)\n",
    "coefficients = full_meta_model.coef_[0]\n",
    "intercept = full_meta_model.intercept_[0]\n",
    "\n",
    "df_coef = pd.DataFrame({\n",
    "    \"model\": list(base_models.keys()),\n",
    "    \"coefficient\": coefficients\n",
    "})\n",
    "\n",
    "print(f\"Intercept: {intercept:.4f}\\n\")\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "727c6ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(df_coef[\"model\"], df_coef[\"coefficient\"], color=\"mediumseagreen\")\n",
    "plt.axvline(0, color=\"black\", linestyle=\"-\", linewidth=0.8)\n",
    "plt.xlabel(\"Logistic Regression Coefficient\")\n",
    "plt.title(\"Meta-model weights for each base model\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
